{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M4-IBVMSoZfv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate\n",
    "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# to get access to google drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBiW2-X4omvz",
    "outputId": "577ebdc6-1e3c-4bfd-c70f-f8e9a0c3b887",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# for google drive case in colab\n",
    "\n",
    "path = \"/content/drive/MyDrive/gan\""
   ],
   "metadata": {
    "id": "GtTZ1S8looYF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41SjjGFroZgH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# for dataset with girls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZEILC1TWoZgH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# one_hot encoding for text \n",
    "import pickle\n",
    "\n",
    "\n",
    "text_path = path+\"/girls_dataset/Text/00_Female/\"\n",
    "\n",
    "\n",
    "dataset_train_path = path+\"/girls_dataset/Train/filenames.pickle\"\n",
    "dataset_test_path =  path+\"/girls_dataset/Test/filenames.pickle\"\n",
    "\n",
    "# girls dataset open .pickle filenames\n",
    "\n",
    "train_names = []\n",
    "test_names = []\n",
    "\n",
    "with open(dataset_train_path, 'rb') as f:\n",
    "    images_train_names = pickle.load(f)\n",
    "    \n",
    "for name in images_train_names:\n",
    "    # print(name)\n",
    "    image_name = name[10:]\n",
    "    # image_name = name.removeprefix(\"00_Female/\")\n",
    "    train_names.append(image_name)\n",
    "    \n",
    "with open(dataset_test_path, 'rb') as f:\n",
    "    images_test_names = pickle.load(f)\n",
    "\t\n",
    "for name in images_test_names:\n",
    "    image_name = name[10:]\n",
    "    # image_name = name.removeprefix(\"00_Female/\")\n",
    "    test_names.append(image_name)\t\n",
    "\n",
    "\n",
    "train_text_list = []\n",
    "test_text_list = []\n",
    "\n",
    "for file in os.listdir(text_path):\n",
    "    with open(text_path+file) as f:\n",
    "        a = f.read()\n",
    "        # file.removesuffix(\".txt\")\n",
    "        if file[:5] in train_names:\n",
    "            train_text_list.append(a)\n",
    "        if file[:5] in test_names:\n",
    "            test_text_list.append(a) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0IBC3HBoZgI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Custom Word2Vec Model in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Bt-QQQQGoZgI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors,Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# For visualization of word2vec model\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Text Preprocessing\n",
    "preprocessed_text_train = list(map(simple_preprocess,train_text_list))\n",
    "preprocessed_text_test = list(map(simple_preprocess,test_text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rud-g7bEoZgJ",
    "outputId": "99d9eb40-8467-4cdc-bc72-959767a4ac4b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "169\n",
      "120\n",
      "171\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "# count the mean len of tokenized texts\n",
    "mean1 = 0\n",
    "min1 = 999\n",
    "for token_text in preprocessed_text_train:\n",
    "    mean1+=len(token_text)\n",
    "    min1 = min(min1, len(token_text))\n",
    "print(mean1//500)\n",
    "print(min1)\n",
    "\n",
    "mean1 = 0\n",
    "min1 = 999\n",
    "for token_text in preprocessed_text_test:\n",
    "    mean1+=len(token_text)\n",
    "    min1 = min(min1, len(token_text))\n",
    "print(mean1//260)\n",
    "print(min1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkDlYjQToZgJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZXvwVczoZgJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training the embedding\n",
    "\n",
    "model_cbow_train = Word2Vec(sentences=preprocessed_text_train,\n",
    "sg=0, min_count=1, workers=4, window =5, iter = 100,size=9)\n",
    "\n",
    "model_cbow_test = Word2Vec(sentences=preprocessed_text_test,\n",
    "sg=0, min_count=1, workers=4, window =5, iter = 100,size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNUtHazfoZgK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make embeddedings\n",
    "\n",
    "train_text_embedded = []\n",
    "test_text_embedded = []\n",
    "\n",
    "for index,token_sentence in enumerate(preprocessed_text_train):\n",
    "    train_text_embedded.append(list())\n",
    "    for word in token_sentence[:120]:\n",
    "    \n",
    "        try:\n",
    "            vector = model_cbow_train.wv.get_vector(word)\n",
    "            train_text_embedded[index].append(vector)\n",
    "        except:\n",
    "            print(\"no word as a key\")\n",
    "            \n",
    "for index,token_sentence in enumerate(preprocessed_text_test):\n",
    "    test_text_embedded.append(list())\n",
    "    for word in token_sentence[:120]:\n",
    "    \n",
    "        try:\n",
    "            vector = model_cbow_test.wv.get_vector(word)\n",
    "            test_text_embedded[index].append(vector)\n",
    "        except:\n",
    "            print(\"no word as a key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BmV4HyMGoZgK",
    "outputId": "e30a2786-fdcc-4391-c87d-5ef7a4f3461a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(500, 120, 9)\n",
      "(260, 120, 9)\n"
     ]
    }
   ],
   "source": [
    "# convert to mu,py array\n",
    "train_text_embedded = np.array(train_text_embedded)\n",
    "print(train_text_embedded.shape)\n",
    "test_text_embedded = np.array(test_text_embedded)\n",
    "print(test_text_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jmme3Ev0oZgK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save the models\n",
    "\n",
    "import pickle\n",
    "\n",
    "path = path+\"/init_embedding_values_girls/\"\n",
    "\n",
    "with open(f'{path}embed_train.pickle', 'wb') as f:\n",
    "    pickle.dump(train_text_embedded, f)\n",
    "\n",
    "with open(f'{path}embed_test.pickle', 'wb') as f:\n",
    "    pickle.dump(test_text_embedded, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0oVwLxuoZgL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "    \n",
    "    for word in model.wv.key_to_index:\n",
    "        \n",
    "        tokens.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Drlo5J11oZgL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tsne_plot(model_cbow_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ELMo embedding"
   ],
   "metadata": {
    "id": "Zrsw1J0ZirQJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "id": "35KeAuxcXihB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/elmo/3\")"
   ],
   "metadata": {
    "id": "v6RQiaf4bp2p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_text_list = []\n",
    "test_text_list = []\n",
    "\n",
    "\n",
    "for text in preprocessed_text_train:\n",
    "  train_text_list.append(\" \".join(text))\n",
    "\n",
    "for text in preprocessed_text_test:\n",
    "  test_text_list.append(\" \".join(text))\n"
   ],
   "metadata": {
    "id": "hXBdWa1Nm0Fn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "[test_text_list[0]]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvENKRGrnPWM",
    "outputId": "e27d0b05-790c-455c-fcd4-ad19f647deb3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['this woman turns her face towards the front side this woman is about to years old and has big brown eyes with double eyelids and long eyelashes thick flat eyebrows and dark brown skin woman with thick bushy eyebrows big eyes with long eyelashes and square face this woman has medium nose medium glamour mouth and square shape face this woman is about to years old with brown braid hair long shape face and olive skin this woman has big bright eyes thick bushy eyebrows medium nose and natural mouth woman has long shape face dark brown skin and brown braid hair woman has brown hair with pink hood covering ears and olive skin the woman has square shape face with big nose natural mouth big bright eyes thick flat eyebrows and long brown braid hair with pink scarf']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_text_list_embed = []\n",
    "test_text_list_embed = []\n",
    "\n",
    "for index,data_part in enumerate([train_text_list,test_text_list]):\n",
    "  for text in data_part:\n",
    "    if index == 0:\n",
    "      train_bededding = embed.signatures['default'](tf.constant([text]))\n",
    "      train_text_list_embed.append(train_bededding[\"default\"])\n",
    "    else:\n",
    "      test_bededding = embed.signatures['default'](tf.constant([text]))\n",
    "      test_text_list_embed.append(test_bededding[\"default\"])"
   ],
   "metadata": {
    "id": "mLdbl9OjbuGA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_bededding = np.array(train_text_list_embed)\n",
    "test_bededding = np.array(test_text_list_embed)"
   ],
   "metadata": {
    "id": "VPigyGA_d8jh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_bededding.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oo3laok2h8hh",
    "outputId": "6f1a9c6c-f2d3-43ae-c908-c55e37712227",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d974c4b7c9167b3c2df7ef2f40c9ab050914ef25a32a81d1263224e0dc77032"
   }
  },
  "colab": {
   "name": "Embedding.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "gpuClass": "standard",
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}