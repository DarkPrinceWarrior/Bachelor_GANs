{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6c8wajLAlb00",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# to get access to google drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "bEpYtV-AoWp2",
    "outputId": "4784165d-7f70-4c5c-fb21-08d1c8064c2c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# for google drive case in colab\n",
    "\n",
    "path = \"/content/drive/MyDrive/gan\""
   ],
   "metadata": {
    "id": "eE7twQGpmVOt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MV2nxbV9lb09",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Conditioning Augmentation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zbdDLfrplb1A",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# conditioned by the text.\n",
    "def conditioning_augmentation(x):\n",
    "\t\"\"\"The mean_logsigma passed as argument is converted into the text conditioning variable.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The output of the text embedding passed through a FC layer with LeakyReLU non-linearity.\n",
    "\n",
    "\tReturns:\n",
    "\t \tc: The text conditioning variable after computation.\n",
    "\t\"\"\"\n",
    "\tmean = x[:, :128]\n",
    "\tlog_sigma = x[:, 128:]\n",
    "\n",
    "\tstddev = tf.math.exp(log_sigma)\n",
    "\tepsilon = K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32'))\n",
    "\tc = mean + stddev * epsilon\n",
    "\treturn c\n",
    "\n",
    "def build_ca_network():\n",
    "\t\"\"\"Builds the conditioning augmentation network.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(1024,)) #size of the vocabulary in the text data\n",
    "\tmls = Dense(256)(input_layer1)\n",
    "\tmls = LeakyReLU(alpha=0.2)(mls)\n",
    "\tca = Lambda(conditioning_augmentation)(mls)\n",
    "\treturn Model(inputs=[input_layer1], outputs=[ca])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXZhDmmJlb1D",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Stage 1 Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0v1MHgKKlb1F",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def UpSamplingBlock(x, num_kernels, index=0):\n",
    "\t\"\"\"An Upsample block with Upsampling2D, Conv2D, BatchNormalization and a ReLU activation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The preceding layer as input.\n",
    "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
    "\n",
    "\tReturns:\n",
    "\t\tx: The final activation layer after the Upsampling block.\n",
    "\t\"\"\"\n",
    "  \n",
    "\t# x = Conv2DTranspose(num_kernels, kernel_size=(2,2), strides=(2,2))(x)\n",
    "\n",
    "\tx = UpSampling2D(size=(2,2))(x) # was originally\n",
    "\tx = Conv2D(num_kernels, kernel_size=(3,3), padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x) #prevent from mode collapse\n",
    "\tx = LeakyReLU(alpha=0.2)(x) # ReLU(x)\n",
    "\tx = Dropout(0.5)(x) # custom\n",
    "\treturn x\n",
    "\n",
    "\n",
    "def build_stage1_generator():\n",
    "\n",
    "\tinput_layer1 = Input(shape=(1024,))\n",
    "\tca = Dense(256)(input_layer1)\n",
    "\tca = LeakyReLU(alpha=0.2)(ca)\n",
    "\n",
    "\t# Obtain the conditioned text\n",
    "\tc = Lambda(conditioning_augmentation)(ca)\n",
    "\n",
    "\tinput_layer2 = Input(shape=(100,))\n",
    "\tconcat = Concatenate(axis=1)([c, input_layer2])\n",
    "\n",
    "\tx = Dense(16384, use_bias=False)(concat) \n",
    "\tx = LeakyReLU()(x) # ReLU\n",
    "\tprint(x.shape)\n",
    "\tx = Reshape((4, 4, 1024), input_shape=(16384,))(x)\n",
    " \n",
    "\tx = UpSamplingBlock(x, 512)\n",
    "\tx = UpSamplingBlock(x, 256)  # upsampled our image to 64*64*3 \n",
    "\tx = UpSamplingBlock(x, 128,index=1)  # upsampled our image to 64*64*3 \n",
    "\tx = UpSamplingBlock(x, 64, index=1)  # upsampled our image to 64*64*3 \n",
    "\n",
    "\tx = Conv2D(3, kernel_size=3, padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = Activation('tanh')(x)\n",
    "\n",
    "\tstage1_gen = Model(inputs=[input_layer1, input_layer2], outputs=[x, ca]) \n",
    "\treturn stage1_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_LKwfpAlb1H",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Stage 1 Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4OiA-hYmlb1I",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ConvBlock(x, num_kernels, kernel_size=(4,4), strides=2, activation=True):\n",
    "\t\"\"\"A ConvBlock with a Conv2D, BatchNormalization and LeakyReLU activation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The preceding layer as input.\n",
    "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
    "\n",
    "\tReturns:\n",
    "\t\tx: The final activation layer after the ConvBlock block.\n",
    "\t\"\"\"\n",
    "\tx = Conv2D(num_kernels, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\t\n",
    "\tif activation:\n",
    "\t\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\treturn x\n",
    "\n",
    "\n",
    "def build_embedding_compressor():\n",
    "\n",
    "\t\"\"\"Build embedding compressor model\n",
    "\t\"\"\"\n",
    "\n",
    "\tinput_layer1 = Input(shape=(1024,))\n",
    "\tx = Dense(128)(input_layer1)\n",
    "\tx = LeakyReLU()(x) # ReLU\n",
    "\n",
    "\n",
    "\tmodel = Model(inputs=[input_layer1], outputs=[x])\n",
    "\treturn model\n",
    "\n",
    "\n",
    "\n",
    "# the discriminator is fed with two inputs, the feature from Generator and the text embedding\n",
    "def build_stage1_discriminator():\n",
    "\t\"\"\"Builds the Stage 1 Discriminator that uses the 64x64 resolution images from the generator\n",
    "\tand the compressed and spatially replicated embedding.\n",
    "\n",
    "\tReturns:\n",
    "\t\tStage 1 Discriminator Model for StackGAN.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tinput_layer1 = Input(shape=(64, 64, 3))  \n",
    "\n",
    "\tx = Conv2D(64, kernel_size=(4,4), strides=2, padding='same', use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(input_layer1)\t\t\n",
    "\t\t\t\t\n",
    "\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\tx = ConvBlock(x, 128)\n",
    "\tx = ConvBlock(x, 256)\n",
    "\tx = ConvBlock(x, 512)\n",
    "\n",
    "\t# Obtain the compressed and spatially replicated text embedding\n",
    "\tinput_layer2 = Input(shape=(4, 4, 128)) #2nd input to discriminator, text embedding\n",
    "\tconcat = concatenate([x, input_layer2])\n",
    "\n",
    "\tx1 = Conv2D(512, kernel_size=(1,1), padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(concat)\n",
    "\tx1 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\tx1 = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\t# Flatten and add a FC layer to predict.\n",
    "\tx1 = Flatten()(x1)\n",
    "\tx1 = Dense(1)(x1)\n",
    "\tx1 = Activation('sigmoid')(x1)\n",
    "\n",
    "\tstage1_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x1])  \n",
    "\treturn stage1_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjFOPtlnlb1L",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Stage 1 Adversarial Model (Building a GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_ksYdIJVlb1M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Building GAN with Generator and Discriminator\n",
    "\n",
    "def build_adversarial(generator_model, discriminator_model):\n",
    "\t\"\"\"Stage 1 Adversarial model.\n",
    "\n",
    "\tArgs:\n",
    "\t\tgenerator_model: Stage 1 Generator Model\n",
    "\t\tdiscriminator_model: Stage 1 Discriminator Model\n",
    "\n",
    "\tReturns:\n",
    "\t\tAdversarial Model.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(1024,))  \n",
    "\tinput_layer2 = Input(shape=(100,)) \n",
    "\tinput_layer3 = Input(shape=(4, 4, 128)) \n",
    "\n",
    "\tx, ca = generator_model([input_layer1, input_layer2]) #text,noise\n",
    "\n",
    "\tdiscriminator_model.trainable = False \n",
    "\n",
    "\tprobabilities = discriminator_model([x, input_layer3]) \n",
    "\tadversarial_model = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=[probabilities, ca])\n",
    "\treturn adversarial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6zjdctKlb1O",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Bg2PWV8Ylb1P",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the loss function of completed model\n",
    "import pickle\n",
    "\n",
    "def adversarial_loss(y_true, y_pred):\n",
    "\tmean = y_pred[:, :128]\n",
    "\tls = y_pred[:, 128:]\n",
    "\tloss = -ls + 0.5 * (-1 + tf.math.exp(2.0 * ls) + tf.math.square(mean))\n",
    "\tloss = K.mean(loss)\n",
    "\treturn loss\n",
    "\n",
    "\n",
    "def normalize(input_image, real_image):\n",
    "\tinput_image = (input_image / 127.5) - 1\n",
    "\treal_image = (real_image / 127.5) - 1\n",
    "\n",
    "\treturn input_image, real_image\n",
    "\n",
    "\n",
    "\n",
    "def load_text_embeddings(text_embeddings):\n",
    "    \n",
    "\t\twith open(text_embeddings, 'rb') as f:\n",
    "\t\t\tembeds = pickle.load(f)\n",
    "\t\t\n",
    "\t\treturn embeds\n",
    "    \n",
    "\n",
    "# for girls dataset\n",
    "def load_bbox(data_path):\n",
    "\tb_boxes_list = []\n",
    "\t\n",
    "\twith open(data_path) as file:\n",
    "\t\tfor line in file:\n",
    "\t\t\trow = line.rstrip().split()\n",
    "\t\t\tb_boxes_list.append(row[1:])\n",
    "\treturn b_boxes_list\n",
    "    \n",
    "\n",
    "def save_image(file, save_path):\n",
    "\t\"\"\"Saves the image at the specified file path.\n",
    "\t\"\"\"\n",
    "\timage = plt.figure()\n",
    "\tax = image.add_subplot(1,1,1)\n",
    "\tax.imshow(file)\n",
    "\tax.axis(\"off\")\n",
    "\tplt.savefig(save_path)\n",
    "\n",
    "\n",
    "def load_data(dataset_path, embeddings_path):\n",
    "\t\"\"\"load dataset\"\"\"\n",
    "\t\n",
    "\tembeddings = load_text_embeddings(embeddings_path)\n",
    "\tx, embeds  = [],[]\n",
    "\tbbox_list = load_bbox(path+\"/girls_dataset/bounding_boxes.txt\")\n",
    "\n",
    "\tindex = 0\n",
    "\t\n",
    "\t\n",
    "\t# girls dataset open .pickle filenames\n",
    "\timages_path = path+\"/girls_dataset/Image/00_Female/\"\n",
    "\twith open(dataset_path, 'rb') as f:\n",
    "\t\timages_names = pickle.load(f)\n",
    "\t\n",
    "\tfor name in images_names:\n",
    "\t\timage_name = name[10:]+\".png\"\n",
    "\t\t# image_name = name.removeprefix(\"00_Female/\")+\".png\"\n",
    "\t\t\n",
    "\t\t# load image from path\n",
    "\t\timage = Image.open(images_path+image_name)\n",
    "\t\t\n",
    "\t\tbounds_list_values = bbox_list[index]\n",
    "\t\ta = list(map(float, bounds_list_values))\n",
    "\t\tbounding_box = list(map(int, a))\n",
    "\t\t# crop image\n",
    "\t\tif bounding_box is not None:\n",
    "\t\t\timage = image.crop(bounding_box)\n",
    "\t\t\t\n",
    "\t\n",
    "\t\timage = image.resize((64,64), PIL.Image.BILINEAR)\n",
    "\t\ttry:\n",
    "\t\t\te = embeddings[index, :, :]\n",
    "\t\t\tx.append(np.array(image))\n",
    "\t\t\tembeds.append(e.reshape(-1))\n",
    "\t\t\t\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f'{e}')\n",
    "\t\t\t\n",
    "\t\t# move to the next image and embed\n",
    "\t\tindex+=1\n",
    "\t\t# if dataset_path == \"train/\" and index == 4500:\n",
    "\t\t# \tbreak\n",
    "\t\t# elif dataset_path == \"test/\" and index == 700:\n",
    "\t\t# \tbreak\n",
    "\t\n",
    "\tx = np.array(x)\n",
    "\tembeds = np.array(embeds)\n",
    "\t\n",
    "\treturn x, embeds\n",
    "\t\n",
    "\t# for file_name in os.listdir(dataset_path):\n",
    "\t\t\n",
    "\t\n",
    "\t# \t# load image from path\n",
    "\t# \timage = Image.open(dataset_path+file_name)\n",
    "\t\t\n",
    "\t# \tbounds_list_values = bbox_list[index]\n",
    "\t# \ta = list(map(float, bounds_list_values))\n",
    "\t# \tbounding_box = list(map(int, a))\n",
    "\t\t\n",
    "\t# \t# crop image\n",
    "\t# \tif bounding_box is not None:\n",
    "\t# \t\timage = image.crop(bounding_box)\n",
    "\t\t\t\n",
    "\t\n",
    "\t# \timage = image.resize((64,64), PIL.Image.Resampling.BILINEAR)\n",
    "\t# \ttry:\n",
    "\t# \t\te = embeddings[index, :, :]\n",
    "\t# \t\tx.append(np.array(image))\n",
    "\t# \t\tembeds.append(e)\n",
    "\t\t\t\n",
    "\t# \texcept Exception as e:\n",
    "\t# \t\tprint(f'{e}')\n",
    "\t\t\t\n",
    "\t# \t# move to the next image and embed\n",
    "\t# \tindex+=1\n",
    "\t# \tif dataset_path == \"train/\" and index == 4500:\n",
    "\t# \t\tbreak\n",
    "\t# \telif dataset_path == \"test/\" and index == 700:\n",
    "\t# \t\tbreak\n",
    "\t\n",
    "\t# x = np.array(x)\n",
    "\t# embeds = np.array(embeds)\n",
    "\t\n",
    "\t# return x, embeds\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class StackGanStage1(object):\n",
    "    \n",
    "\n",
    "\tdef __init__(self, epochs=1000, z_dim=100, batch_size=64, enable_function=True, \n",
    "\t\tstage1_generator_lr=0.0002, stage1_discriminator_lr=0.0002):\n",
    "\n",
    "\t\t\n",
    "\n",
    "        # StackGAN hyperparameters\n",
    "\t\tself.epochs = epochs\n",
    "\t\tself.z_dim = z_dim\n",
    "\t\tself.enable_function = enable_function\n",
    "\t\tself.stage1_generator_lr = stage1_generator_lr\n",
    "\t\tself.stage1_discriminator_lr = stage1_discriminator_lr\n",
    "\t\tself.image_size = 64\n",
    "\t\tself.conditioning_dim = 128\n",
    "\t\tself.batch_size = batch_size\n",
    "\n",
    "  \n",
    "\n",
    "\t\t# ADAM optimizer for both models of DIS and GEN\n",
    "\t\tself.stage1_generator_optimizer = Adam(learning_rate=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t\tself.stage1_discriminator_optimizer = Adam(learning_rate=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t\t# self.stage1_discriminator_optimizer = SGD(learning_rate=0.1, momentum=0.9)\n",
    "\t\t\t\n",
    "        # create the generator model of 1st stage \n",
    "\t\tself.stage1_generator = build_stage1_generator()\n",
    "\t\tself.stage1_generator.compile(loss='mse', optimizer=self.stage1_generator_optimizer)\n",
    "\t\t\n",
    "\t\t# load model weights after 150 epochs\n",
    "\t\t# self.stage1_generator.load_weights(\"weights/stage1_gen.h5\")\n",
    "\n",
    "        # create the discriminator model of 1st stage \n",
    "\t\tself.stage1_discriminator = build_stage1_discriminator()\n",
    "\t\tself.stage1_discriminator.compile(loss='binary_crossentropy', \n",
    "                                    optimizer=self.stage1_discriminator_optimizer)\n",
    "                                    \n",
    "        # load model weights after 150 epochs\n",
    "\t\t# self.stage1_discriminator.load_weights(\"weights/stage1_disc.h5\")\n",
    "        \n",
    "        # create the block(network) that perfoms Conditional Augmentation with embeddings \n",
    "\t\tself.ca_network = build_ca_network()\n",
    "\t\tself.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "        \n",
    "        # load model weights after 150 epochs\n",
    "\t\t# self.ca_network.load_weights(\"weights/stage1_ca.h5\")\n",
    "        \n",
    "\t\tself.embedding_compressor = build_embedding_compressor()\n",
    "\t\tself.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\t\t\n",
    "\t\t# load model weights after 150 epochs\n",
    "\t\t# self.embedding_compressor.load_weights(\"weights/stage1_embco.h5\")\n",
    "\n",
    "        # create the completed GAN model \n",
    "\t\tself.stage1_adversarial = build_adversarial(self.stage1_generator, self.stage1_discriminator)\n",
    "  \n",
    "\t\tself.stage1_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], \n",
    "                                  loss_weights=[1, 2.0], \n",
    "                                  optimizer=self.stage1_generator_optimizer)\n",
    "                                  \n",
    "        # load model weights after 150 epochs\n",
    "\t\t# self.stage1_adversarial.load_weights(\"weights/stage1_adv.h5\")\n",
    "         \n",
    "         \n",
    "\t\tself.checkpoint1 = tf.train.Checkpoint(\n",
    "\t\t\t\tgenerator_optimizer=self.stage1_generator_optimizer,\n",
    "\t\t\t\tdiscriminator_optimizer=self.stage1_discriminator_optimizer,\n",
    "\t\t\t\tgenerator=self.stage1_generator,\n",
    "\t\t\t\tdiscriminator=self.stage1_discriminator)\n",
    "\n",
    "\n",
    "\tdef train_stage1(self):\n",
    "\t\t\"\"\"Trains the stage1 StackGAN.\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# for girls dataset\n",
    "\n",
    "\t\tpath = \"/content/drive/MyDrive/gan\"\n",
    "\n",
    "\t\tdataset_train_path = path+\"/girls_dataset/Train/filenames.pickle\"\n",
    "\t\tdataset_test_path =  path+\"/girls_dataset/Test/filenames.pickle\"\n",
    "\t\tembeddings_path_train_file = path+\"/init_embedding_values_girls/embed_train.pickle\"\n",
    "\t\tembeddings_path_test_file = path+\"/init_embedding_values_girls/embed_test.pickle\"\n",
    "\t\t\n",
    "\t\tx_train, train_embeds = load_data(dataset_path=dataset_train_path, embeddings_path=embeddings_path_train_file)\n",
    "\n",
    "\t\tx_test, test_embeds = load_data(dataset_path=dataset_test_path, embeddings_path=embeddings_path_test_file)\n",
    "\t\t\n",
    "\t\tprint(len(x_test),len(test_embeds))\n",
    "\t\tprint(len(x_train),len(train_embeds))\n",
    "\t\t\n",
    "\t\tprint(x_test.shape,test_embeds.shape)\n",
    "\t\tprint(x_train.shape,train_embeds.shape)\n",
    "\t\t\n",
    "\n",
    "\t\treal = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
    "\t\tfake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
    "\n",
    "\t\tfor epoch in range(self.epochs):\n",
    "\t\t\tprint(f'EPOCH: {epoch}')\n",
    "\n",
    "\t\t\tgen_loss = []\n",
    "\t\t\tdis_loss = []\n",
    "\n",
    "\t\t\tnum_batches = int(x_train.shape[0] / self.batch_size)\n",
    "\n",
    "\t\t\tfor i in range(num_batches):\n",
    "\n",
    "\t\t\t\tlatent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t\t\tembedding_text = train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\t\t\t\tcompressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
    "\t\t\t\tcompressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, 128))\n",
    "\t\t\t\tcompressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\n",
    "\t\t\t\timage_batch = x_train[i * self.batch_size:(i+1) * self.batch_size]\n",
    "\t\t\t\timage_batch = (image_batch - 127.5) / 127.5\n",
    "\n",
    "\t\t\t\tgen_images, _ = self.stage1_generator.predict([embedding_text, latent_space])\n",
    "\n",
    "\t\t\t\tdiscriminator_loss = self.stage1_discriminator.train_on_batch([image_batch, compressed_embedding], \n",
    "\t\t\t\t\t\tnp.reshape(real, (self.batch_size, 1)))\n",
    "\n",
    "\t\t\t\tdiscriminator_loss_gen = self.stage1_discriminator.train_on_batch([gen_images, compressed_embedding],\n",
    "\t\t\t\t\t\tnp.reshape(fake, (self.batch_size, 1)))\n",
    "\n",
    "\t\t\t\tdiscriminator_loss_wrong = self.stage1_discriminator.train_on_batch([gen_images[: self.batch_size-1], \n",
    "\t\t\t\tcompressed_embedding[1:]], \n",
    "\t\t\t\t\t\tnp.reshape(fake[1:], (self.batch_size-1, 1)))\n",
    "\n",
    "\t\t\t\t# Discriminator loss\n",
    "\t\t\t\td_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_wrong))\n",
    "\t\t\t\tdis_loss.append(d_loss)\n",
    "\t\t\t\t\n",
    "\t\t\t\tprint(f'Discriminator Loss: {d_loss}')\n",
    "\n",
    "\t\t\t\t# Generator loss\n",
    "\t\t\t\tg_loss = self.stage1_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
    "\t\t\t\t\t\t[K.ones((self.batch_size, 1)) * 0.9, K.ones((self.batch_size, 256)) * 0.9])\n",
    "\n",
    "\t\t\t\tprint(f'Generator Loss: {g_loss}')\n",
    "\t\t\t\tgen_loss.append(g_loss)\n",
    "\n",
    "\t\t\t\tif epoch % 5 == 0:\n",
    "\t\t\t\t\t\tlatent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t\t\t\t\tembedding_batch = test_embeds[0 : self.batch_size]\n",
    "\t\t\t\t\t\tgen_images, _ = self.stage1_generator.predict_on_batch([embedding_batch, latent_space])\n",
    "\n",
    "\t\t\t\t\t\tfor i, image in enumerate(gen_images[:10]):\n",
    "\t\t\t\t\t\t\tsave_image(image, path+f'/image_test_result_stage_1/gen_1_{epoch}_{i}')\n",
    "\n",
    "\t\t\t\t# we trained weights up to 25 epoch so we start from 25\n",
    "\t\t\t\t# if epoch > 25:\n",
    "\n",
    "\t\t\t\tpath = path+\"/\"\n",
    "\t\t\t\tif epoch % 25 == 0:\n",
    "\t\t\t\t\tself.stage1_generator.save_weights(path+'weights_stage_1/stage1_gen.h5')\n",
    "\t\t\t\t\tself.stage1_discriminator.save_weights(path+\"weights_stage_1/stage1_disc.h5\")\n",
    "\t\t\t\t\tself.ca_network.save_weights(path+'weights_stage_1/stage1_ca.h5')\n",
    "\t\t\t\t\tself.embedding_compressor.save_weights(path+'weights_stage_1/stage1_embco.h5')\n",
    "\t\t\t\t\tself.stage1_adversarial.save_weights(path+'weights_stage_1/stage1_adv.h5')  \n",
    "\t\t \n",
    "      # if gradient of gen is out of 100 each batch so then we finish training after 30 epochs \n",
    "\t\t\tif epoch > 1 and np.sum(gen_loss) > 600:\n",
    "\t\t\t\tbreak \n",
    "\n",
    "\t\tself.stage1_generator.save_weights(path+'weights_stage_1/stage1_gen.h5')\n",
    "\t\tself.stage1_discriminator.save_weights(path+\"weights_stage_1/stage1_disc.h5\")\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "id": "jFcdv-pruLfg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_text_embeddings(text_embeddings):\n",
    "    \n",
    "\t\twith open(text_embeddings, 'rb') as f:\n",
    "\t\t\tembeds = pickle.load(f)\n",
    "\t\t\n",
    "\t\treturn embeds\n",
    "\n",
    "\n",
    "def load_data_predict(embeddings_path):\n",
    "  \"\"\"load text\"\"\"\n",
    "\n",
    "  embeddings = load_text_embeddings(embeddings_path)\n",
    "  embeds  = []\n",
    "\n",
    "  try:\n",
    "    e = embeddings[0, :, :]\n",
    "    embeds.append(e.reshape(-1))\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f'{e}')\n",
    "\n",
    "\n",
    "  embeds = np.array(embeds)\n",
    "\n",
    "  return embeds\n",
    "\t"
   ],
   "metadata": {
    "id": "0h0nDhZiqG8k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Predict the image**"
   ],
   "metadata": {
    "id": "P4tviLa8Yw3b",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "class StackGanStage1(object):\n",
    "    \n",
    "\n",
    "\tdef __init__(self, epochs=1000, z_dim=100, enable_function=True, \n",
    "\t\tstage1_generator_lr=0.0002, stage1_discriminator_lr=0.0002):\n",
    "\n",
    "\t\n",
    "    # StackGAN hyperparameters\n",
    "\t\tself.z_dim = z_dim\n",
    "\t\tself.batch_size = 1\n",
    "\t\tself.enable_function = enable_function\n",
    "\t\tself.stage1_generator_lr = stage1_generator_lr\n",
    "\t\tself.stage1_discriminator_lr = stage1_discriminator_lr\n",
    "\t\tself.image_size = 64\n",
    "\t\tself.conditioning_dim = 128\n",
    "\n",
    "\t\tpath = \"/content/drive/MyDrive/gan/\"\n",
    "\n",
    "  \n",
    "\n",
    "\t\t# ADAM optimizer for both models of DIS and GEN\n",
    "\t\tself.stage1_generator_optimizer = Adam(learning_rate=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t\tself.stage1_discriminator_optimizer = Adam(learning_rate=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t\t# self.stage1_discriminator_optimizer = SGD(learning_rate=0.1, momentum=0.9)\n",
    "\t\t\t\n",
    "        # create the generator model of 1st stage \n",
    "\t\tself.stage1_generator = build_stage1_generator()\n",
    "\t\tself.stage1_generator.compile(loss='mse', optimizer=self.stage1_generator_optimizer)\n",
    "\t\t\n",
    "\t\t# load model weights after 600 epochs\n",
    "\t\tself.stage1_generator.load_weights(path+\"weights_stage_1/stage1_gen.h5\")\n",
    "\n",
    "        # create the discriminator model of 1st stage \n",
    "\t\tself.stage1_discriminator = build_stage1_discriminator()\n",
    "\t\tself.stage1_discriminator.compile(loss='binary_crossentropy', \n",
    "                                    optimizer=self.stage1_discriminator_optimizer)\n",
    "                                    \n",
    "    # load model weights after 600 epochs\n",
    "\t\tself.stage1_discriminator.load_weights(path+\"weights_stage_1/stage1_disc.h5\")\n",
    "        \n",
    "    # create the block(network) that perfoms Conditional Augmentation with embeddings \n",
    "\t\tself.ca_network = build_ca_network()\n",
    "\t\tself.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "        \n",
    "    # load model weights after 600 epochs\n",
    "\t\tself.ca_network.load_weights(path+\"weights_stage_1/stage1_ca.h5\")\n",
    "        \n",
    "\t\tself.embedding_compressor = build_embedding_compressor()\n",
    "\t\tself.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\t\t\n",
    "\t\t# load model weights after 600 epochs\n",
    "\t\tself.embedding_compressor.load_weights(path+\"weights_stage_1/stage1_embco.h5\")\n",
    "\n",
    "    # create the completed GAN model \n",
    "\t\tself.stage1_adversarial = build_adversarial(self.stage1_generator, self.stage1_discriminator)\n",
    "  \n",
    "\t\tself.stage1_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], \n",
    "                                  loss_weights=[1, 2.0], \n",
    "                                  optimizer=self.stage1_generator_optimizer)\n",
    "                                  \n",
    "    # load model weights after 600 epochs\n",
    "\t\tself.stage1_adversarial.load_weights(path+\"weights_stage_1/stage1_adv.h5\")\n",
    "         \n",
    "        \n",
    "\n",
    "\n",
    "\tdef predict_image_generation(self):\n",
    "\t\t\"\"\"Predict the image StackGAN.\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\t# for girls dataset\n",
    "\n",
    "\t\tpath = \"/content/drive/MyDrive/gan\"\n",
    "\n",
    "\t\tembeddings_path_text_file = path+\"/init_embedding_values_girls_predict/embed_text_predict.pickle\"\n",
    "\t\t\n",
    "\t\ttext_embeds = load_data_predict(embeddings_path=embeddings_path_text_file)\n",
    "\t\t\n",
    "\n",
    "\t\treal = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
    "\t\tfake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
    "\n",
    "\t\tlatent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\tembedding_text = text_embeds\n",
    "\t\tcompressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
    "\t\tcompressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, 128))\n",
    "\t\tcompressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\t\n",
    "\n",
    "\t\tdt_now = str(datetime.datetime.now())\n",
    "\t\tprint(dt_now)\n",
    "\t\tgen_images, _ = self.stage1_generator.predict([embedding_text, latent_space])\n",
    "\t\tsave_image(gen_images[0], path+f'/prediction_result/predicted_image_{dt_now[:19]}')\n",
    "\n"
   ],
   "metadata": {
    "id": "9Ji027ryU1Ge",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "stage1 = StackGanStage1()\n",
    "stage1.predict_image_generation()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "9tIGg5mGqEhN",
    "outputId": "116b19aa-262c-43a1-cc40-5b1c352c375a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 62,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(None, 16384)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-06-28 10:23:39.271463\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d974c4b7c9167b3c2df7ef2f40c9ab050914ef25a32a81d1263224e0dc77032"
   }
  },
  "colab": {
   "name": "stage_1.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "gpuClass": "standard",
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}